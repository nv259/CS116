{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwbwjOLpyLEi"
      },
      "source": [
        "\n",
        "# TIỀN XỬ LÝ DỮ LIỆU (PHẦN 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOyTiugYx9BC"
      },
      "source": [
        "Trong lĩnh vực machine learning, việc tiền xử lý dữ liệu đóng vai trò quan trọng để xây dựng những mô hình chính xác và mạnh mẽ. Dữ liệu thô thường gặp phải tình trạng lộn xộn, thiếu sót và không nhất quán. Tiền xử lý dữ liệu bao gồm một loạt các kỹ thuật và nhiệm vụ nhằm biến đổi và tinh chỉnh dữ liệu thô thành một định dạng thích hợp, chuẩn bị cho việc phân tích và huấn luyện mô hình.\n",
        "\n",
        "Bằng cách giải quyết các vấn đề như giá trị thiếu, các ngoại lệ và tỷ lệ biến đổi khác nhau, việc tiền xử lý đảm bảo chất lượng dữ liệu được cải thiện, dẫn đến hiệu suất mô hình cải thiện.\n",
        "\n",
        "Trong cuốn sổ tay Jupyter này, chúng ta sẽ đào sâu vào các bước cơ bản của tiền xử lý dữ liệu. Chúng ta sẽ làm việc thông qua một bài tập thực tế bằng Python, nơi chúng ta sẽ tập trung vào 2 nhiệm vụ cơ bản:\n",
        "\n",
        "* Xác định và xử lý giá trị bị thiếu\n",
        "* Chuẩn hóa dữ liệu\n",
        "\n",
        "Khi kết thúc bài tập này, bạn sẽ đã có được kinh nghiệm thực tế trong việc đánh giá, làm sạch và biến đổi dữ liệu thô thành một định dạng thích hợp cho việc học máy. Những kỹ năng này là nền tảng trong hành trình khoa học dữ liệu, vì chúng đặt ra sân khấu cho các kỹ thuật nâng cao hơn và việc xây dựng mô hình. Vậy thì, hãy bắt đầu và học nghệ thuật tiền xử lý dữ liệu để mở khóa tiềm năng thực sự của những nỗ lực trong lĩnh vực học máy của bạn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsjvfCQwx9BF"
      },
      "source": [
        "### 1. Tải dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U-6vxuHx9BG"
      },
      "source": [
        "Dữ liệu được sử dụng sẽ là dữ liệu về giá nhà, cụ thể như sau:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPTB2Qa5x9BG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = \"data/housing.csv\"\n",
        "df = pd.read_csv(data_path, index_col=0)\n",
        "df_test = df.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqDzzUZwx9BH"
      },
      "source": [
        "### 2. Xác định số phần tử bị thiếu ở mỗi cột"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPWJvxZIx9BH"
      },
      "outputs": [],
      "source": [
        "# Liệt kê số phần tử bị thiếu ở mỗi cột\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqKArO73x9BI"
      },
      "source": [
        "### 3. Loại bỏ những cột có nhiều giá trị bị thiếu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmc9XRstx9BI"
      },
      "source": [
        "**Bài tập**: Hãy viết hàm nhận vào `dataframe` và `threshold` (ngưỡng phần trăm).\n",
        "Trả về `dataframe` mới sau khi đã loại bỏ hết tất cả các cột mà tỉ lệ phần\n",
        "trăm giá trị bị thiếu vượt qua `threshold`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8_TD6b8x9BI"
      },
      "outputs": [],
      "source": [
        "def drop_sparse_columns(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
        "\n",
        "\n",
        "    # BEGIN SOLUTION\n",
        "\n",
        "    # END SOLUTION\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCLhsP8kx9BI"
      },
      "source": [
        "Ta tiến hành loại bỏ những cột có nhiều giá trị bị thiếu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZnCp4H6x9BJ"
      },
      "outputs": [],
      "source": [
        "# Nếu cột có phần trăm giá trị bị thiếu > 60% thì sẽ bị loại bỏ\n",
        "threshold = 0.6\n",
        "df = drop_sparse_columns(df, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLWlfDJLx9BJ"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra với public tests\n",
        "assert df.shape[1] == 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvD4ssSNx9BJ"
      },
      "outputs": [],
      "source": [
        "# Sau khi đã loại bỏ những cột không cần thiết do chứa quá nhiều giá trị bị thiếu\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfDyzmQ9x9BJ"
      },
      "source": [
        "### 4. Lắp đầy những giá trị thiếu ở những cột còn lại"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFQ6zJtbx9BJ"
      },
      "source": [
        "**Bài tập**: Hãy viết các hàm thực hiện điền giá trị bị thiếu vào `dataframe` ứng với\n",
        "với các chiến lược sau: ***min imputation***, ***max imputation***, ***mean imputation***, ***zero imputation***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8cXz3K6x9BJ"
      },
      "outputs": [],
      "source": [
        "def fill_with_min(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    ### END SOLUTION\n",
        "    pass\n",
        "\n",
        "def fill_with_max(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    ### END SOLUTION\n",
        "    pass\n",
        "\n",
        "def fill_with_mean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    ### END SOLUTION\n",
        "    pass\n",
        "\n",
        "def fill_with_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    ### END SOLUTION\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48xPx7QOx9BK"
      },
      "source": [
        "Ta gọi hàm và tạo những `dataframe` mới ứng với từng kiểu điền rỗng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzXSFk24x9BK"
      },
      "outputs": [],
      "source": [
        "min_filled_df = fill_with_max(df)\n",
        "max_filled_df = fill_with_max(df)\n",
        "mean_filled_df = fill_with_mean(df)\n",
        "zero_filled_df = fill_with_zero(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u15m8awox9BK"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra với public tests\n",
        "assert not min_filled_df.isna().any().any()\n",
        "assert not max_filled_df.isna().any().any()\n",
        "assert not mean_filled_df.isna().any().any()\n",
        "assert not zero_filled_df.isna().any().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHlRCFAKx9BK"
      },
      "source": [
        "## 4. Chuẩn hóa dữ liệu\n",
        "Các đặc trưng thường đi kèm với các tỷ lệ biến đổi khác nhau, điều này có thể dẫn đến mô hình thiên vị. Chúng ta sẽ khám phá các kỹ thuật chuẩn hóa phổ biến\n",
        "\n",
        "- Min-Max Scaling: Nó biến đổi các giá trị trong tập dữ liệu về các giá trị trong khoảng từ 0 đến 1.\n",
        "$$ x_{scaled} = {x-x_{min} \\over x_{max} - x_{min}} $$\n",
        "\n",
        "\n",
        ">>>| x | $x_{scaled}$ |\n",
        "|:--------:|:--------:|\n",
        "| 10       | 0.0      |\n",
        "| -20       | 0.5      |\n",
        "| 35       | 0.25      |\n",
        "| 48       | 1.0      |\n",
        "| 53       | 0.75      |\n",
        "\n",
        "- Standard Scaling (Z-score normalization): Nó tính toán giá trị trung bình và độ lệch chuẩn của tập dữ liệu và chuẩn hóa nó bằng cách trừ giá trị trung bình và chia cho độ lệch chuẩn.\n",
        "\n",
        "$$ x_{scaled} = {x- mean_x \\over std_x} $$\n",
        "\n",
        ">>>| x | $x_{scaled}$ |\n",
        "|:--------:|:--------:|\n",
        "| 10       | -0.56     |\n",
        "| -20       | -1.67      |\n",
        "| 35       | 0.36      |\n",
        "| 48       | 0.84     |\n",
        "| 53       | 1.03      |\n",
        "\n",
        " >>>$mean_x=$25.2, $std_x \\approx$27.0658\n",
        "\n",
        " >>>$mean_{x_{scaled}} \\approx$0, $std_{x_{scaled}} \\approx$1\n",
        "\n",
        "- Robust Scaling: RobustScaler là một kỹ thuật sử dụng trung vị và quartiles để giải quyết các bias từ các giá trị ngoại lệ.\n",
        "\n",
        "$$ x_{scaled} = {x-x_{median} \\over x_{75} - x_{25}} $$\n",
        "\n",
        ">>>| x | $x_{scaled}$ |\n",
        "|:--------:|:--------:|\n",
        "| 10       | -0.66     |\n",
        "| -20       | -1.45      |\n",
        "| 35       | 0.0      |\n",
        "| 48       | 0.34     |\n",
        "| 53       | 0.47      |\n",
        "\n",
        "![anh](https://i.imgur.com/MARX2bg.png)\n",
        "\n",
        " Những kỹ thuật này sẽ giúp đưa các đặc trưng về một tỷ lệ chung, ngăn chặn bất kỳ đặc trưng nào chiếm ưu thế trong quá trình học."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aByZhZ4Dx9BK"
      },
      "source": [
        "**Bài tập**: Hãy viết hàm nhận vào `dataframe` và một `object` thuộc một trong ba\n",
        "scaler đã được import bên dưới và trả vể dataframe đã được chuẩn hóa sử dụng scaler đó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmQLxzz-x9BK"
      },
      "outputs": [],
      "source": [
        "# Sử dụng các class scaler có từ thư viện sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoxgX0Buw68x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Tạo DataFrame với một cột dữ liệu\n",
        "data = {'Column1': [10, -20, 35, 48, 53]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Khởi tạo StandardScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Áp dụng StandardScaler vào cột dữ liệu\n",
        "scaled_data = df.apply(lambda col: scaler.fit_transform(col.values.reshape(-1, 1)).flatten())\n",
        "\n",
        "# In kết quả\n",
        "print(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hCRLIGlx9BK"
      },
      "outputs": [],
      "source": [
        "def scale(df: pd.DataFrame, scaler) -> pd.DataFrame:\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    ### END SOLUTION\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqLvNEYlx9BK"
      },
      "source": [
        "Tiến hành tạo các `dataframe` ứng với từng kiểu chuẩn hóa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IshiE5CBx9BL"
      },
      "outputs": [],
      "source": [
        "minmax_scaled_df = scale(mean_filled_df, MinMaxScaler())\n",
        "standard_scaled_df = scale(mean_filled_df, StandardScaler())\n",
        "robust_scaled_df = scale(mean_filled_df, RobustScaler())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}